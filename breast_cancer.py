# -*- coding: utf-8 -*-
"""Breast_cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19-3_RPStlZ1Ty4KmClcfXwzuVgQsnD0m
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

df=pd.read_csv("/content/drive/MyDrive/data.csv")

print('Shape of Diabetes dataset is :',df.shape)
print('Size of Diabetes dataset is  :',df.size)

df

df.columns

df.info()

df = df.drop_duplicates()

import matplotlib
matplotlib.rcParams['figure.figsize'] = (30, 17)
corrmat=df.corr()
sns.heatmap(corrmat, annot=True)

df.drop(["Unnamed: 32"],axis=1,inplace=True)

df.isnull().sum()

df.info()

df['diagnosis'].unique()

#Label Encoding
from sklearn.preprocessing import LabelEncoder
Encode = LabelEncoder()
df['diagnosis'] = Encode.fit_transform(df['diagnosis'])

df['diagnosis'].unique()

df['diagnosis']=df['diagnosis'].astype(int)

df.info()

df.drop(["id"],axis=1,inplace=True)

df

import matplotlib

matplotlib.rcParams['figure.figsize'] = (300, 200)
sns.barplot(x='radius_mean',y='perimeter_mean',data=df)

matplotlib.rcParams['figure.figsize'] = (300, 200)
sns.barplot(x='area_worst',y='area_mean',data=df)

#matplotlib.rcParams['figure.figsize'] = (300, 200)
sns.barplot(x='compactness_se',y='smoothness_se',data=df)

df1 = df[['radius_mean','area_mean','concave points_mean']]
x = pd.DataFrame(df1['radius_mean'].unique())
heatmap_pt = pd.pivot_table(df1,values ='concave points_mean', index=['area_mean'], columns='radius_mean')
sns.heatmap(heatmap_pt,cmap='twilight')

df

df.columns

matplotlib.rcParams['figure.figsize'] = (12, 6)
x = df.drop(['diagnosis'],axis = 1) # drop dependent feature and plot the outliers.
for i in x.columns:
    sns.boxplot(x = i, data = x,color = 'blue')
    plt.xlabel(i)
    plt.show()

from sklearn.preprocessing import QuantileTransformer
x=df
quantile  = QuantileTransformer()
X = quantile.fit_transform(x)
df_new=pd.DataFrame(X)
df_new.columns =['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',
       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',
       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',
       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
       'fractal_dimension_se', 'radius_worst', 'texture_worst',
       'perimeter_worst', 'area_worst', 'smoothness_worst',
       'compactness_worst', 'concavity_worst', 'concave points_worst',
       'symmetry_worst', 'fractal_dimension_worst']

df_new

df_new.info()

matplotlib.rcParams['figure.figsize'] = (12, 6)
corrmat=df_new.corr()
sns.heatmap(corrmat, annot=True)

x = df_new.drop(['diagnosis'],axis = 1)
for i in x.columns:
    sns.boxplot(x = i, data = x,color = 'blue')
    plt.xlabel(i)
    plt.show()

X = df_new.drop(columns='diagnosis', axis=1)
Y = df_new['diagnosis']

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

X_train.shape,Y_train.shape

X_test.shape, Y_test.shape

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.linear_model import LogisticRegression
logic = LogisticRegression()
logic.fit(X_train, Y_train)
Y_pred_lr = logic.predict(X_test)

log_train = round(logic.score(X_train, Y_train) * 100, 2)
log_accuracy = round(accuracy_score(Y_pred_lr, Y_test) * 100, 2)

print("Training Accuracy    :",log_train ,"%")
print("Model Accuracy Score :",log_accuracy ,"%")
print("\033[1m--------------------------------------------------------\033[0m")
print("Classification_Report: \n",classification_report(Y_test,Y_pred_lr))
print("\033[1m--------------------------------------------------------\033[0m")

df_new.iloc[5,:]

# input_data = (2,95,90,40,150,24,0.727000,20)
input_data=(17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189)
# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data) # converting this list into numpy array

# reshape the numpy array as we are predicting for one instance

input_data_reshaped= input_data_as_numpy_array.reshape(1,-1)
print(input_data_reshaped)

predictions = logic.predict(input_data_reshaped)
print(predictions)
if predictions[0] == 1:
    print("M")
else:
    print("B")

a=confusion_matrix(Y_test,Y_pred_lr)
a

matplotlib.rcParams['figure.figsize']=(12,6)
sns.heatmap(a,annot=True,cmap='YlOrRd')

from sklearn.model_selection import GridSearchCV
param_grid = {
    'C': [0.1, 1, 10],                  # Regularization parameter
    'penalty': ['l1', 'l2'],            # Regularization type
    'solver': ['liblinear', 'saga']     # Optimization algorithm
}

# Create the grid search object
grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, cv=5)

# Perform grid search on the training data
grid_search.fit(X_train, Y_train)

# Get the best hyperparameters found by grid search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

logic_tuned = LogisticRegression(**best_params)
logic_tuned.fit(X_train, Y_train)
Y_pred_lr_tuned = logic_tuned.predict(X_test)
log_accuracy_tuned = round(accuracy_score(Y_pred_lr_tuned, Y_test) * 100, 2)
print("Tuned Model Accuracy:", log_accuracy_tuned)

predictions = logic_tuned.predict(input_data_reshaped)
print(predictions)
if predictions[0] == 1:
    print("M")
else:
    print("B")

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train, Y_train)
Y_pred_svc = svc.predict(X_test)

svc_train = round(svc.score(X_train, Y_train) * 100, 2)
svc_accuracy = round(accuracy_score(Y_pred_svc, Y_test) * 100, 2)

print("Training Accuracy    :",svc_train ,"%")
print("Model Accuracy Score :",svc_accuracy ,"%")
print("\033[1m--------------------------------------------------------\033[0m")
print("Classification_Report: \n",classification_report(Y_test,Y_pred_svc))
print("\033[1m--------------------------------------------------------\033[0m")

import pickle
model_name="breast_svm.pkl"
with open(model_name,'wb') as file:
  pickle.dump(svc,file)

predictions = svc.predict(input_data_reshaped)
print(predictions)
if predictions[0] == 1:
    print("M")
else:
    print("B")

b=confusion_matrix(Y_test,Y_pred_svc)
b

matplotlib.rcParams['figure.figsize']=(12,6)
sns.heatmap(b,annot=True)

input_data=(12.47,17.31,	80.45,	480.1,	0.08928,	0.0763,	0.03609,	0.02369,	0.1526,	0.06046,	0.1532,	0.781,	1.253,	11.91,	0.003796,	0.01371,	0.01346,	0.007096,	0.01536,	0.001541,	14.06,	24.34,	92.82,	607.3,	0.1276,	0.2506,	0.2028,	0.1053,	0.3035,	0.07661)
# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data) # converting this list into numpy array

# reshape the numpy array as we are predicting for one instance

input_data_reshaped= input_data_as_numpy_array.reshape(1,-1)
print(input_data_reshaped)

predictions = logic.predict(input_data_reshaped)
print(predictions)
if predictions[0] == 1:
    print("M")
else:
    print("B")